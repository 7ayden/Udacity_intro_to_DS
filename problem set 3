import numpy as np
import pandas
import scipy
import scipy.stats
import matplotlib.pyplot as plt
from ggplot import *

def entries_histogram(turnstile_weather):

    plt.figure()
    plt.xlim([0,6000])
    plt.ylim([0,45000])
    x=turnstile_weather[turnstile_weather['rain']==0]
    y=turnstile_weather[turnstile_weather['rain']==1]    
    x['ENTRIESn_hourly'].hist(label='No rain',bins=300,color = 'b')
    y['ENTRIESn_hourly'].hist(label='Rain',bins=300, color = 'g')
    plt.xlabel("ENTRIESn_hourly")
    plt.ylabel("frequency ")
    plt.title('Histogram of ENTRIESn_hourly')
    plt.legend()
    plt.show()

    return plt


def mann_whitney_plus_means(turnstile_weather):

    df = turnstile_weather
        
    with_rain =  df['ENTRIESn_hourly'][df['rain']==1]
    without_rain =  df['ENTRIESn_hourly'][df['rain']==0]
    
    with_rain_mean = with_rain.mean()
    without_rain_mean = without_rain.mean()
    
    U, p = scipy.stats.mannwhitneyu(with_rain, without_rain)
    
    
    return with_rain_mean, without_rain_mean, U, p # leave this line for the grader
    

def normalize_features(df):
    """
    Normalize the features in the data set.
    """
    mu = df.mean()
    sigma = df.std()

    if (sigma == 0).any():
        raise Exception("One or more features had the same value for all samples, and thus could " + \
                         "not be normalized. Please do not include features with only a single value " + \
                         "in your model.")
    df_normalized = (df - df.mean()) / df.std()

    return df_normalized, mu, sigma

def compute_cost(features, values, theta):
    """
    Compute the cost function given a set of features / values, 
    and the values for our thetas.
    
    This can be the same code as the compute_cost function in the lesson #3 exercises,
    but feel free to implement your own.
    """
    
    # your code here
    m = len(values)
    sum_of_square_errors = np.square(np.dot(features, theta) - values).sum()
    cost = sum_of_square_errors / (2*m)

    return cost

def gradient_descent(features, values, theta, alpha, num_iterations):
    """
    Perform gradient descent given a data set with an arbitrary number of features.
    
    This can be the same gradient descent code as in the lesson #3 exercises,
    but feel free to implement your own.
    """
    
    m = len(values)
    cost_history = []

    for i in range(num_iterations):
        # your code here
        predicted_values = np.dot(features, theta)
        theta = theta - alpha / m * np.dot ((predicted_values - values),features)
        cost = compute_cost(features, values, theta)
        cost_history.append(cost)

    return theta, pandas.Series(cost_history)

def predictions(dataframe):

    # Select Features (try different features!)
    features = dataframe[['rain', 'precipi', 'Hour', 'meantempi']]
    
    # Add UNIT to features using dummy variables
    dummy_units = pandas.get_dummies(dataframe['UNIT'], prefix='unit')
    features = features.join(dummy_units)
    print len(features)
    # Values
    values = dataframe['ENTRIESn_hourly']
    m = len(values)

    features, mu, sigma = normalize_features(features)
    features['ones'] = np.ones(m) # Add a column of 1s (y intercept)
    
    # Convert features and values to numpy arrays
    features_array = np.array(features)
    values_array = np.array(values)

    # Set values for alpha, number of iterations.
    alpha = 0.04 # please feel free to change this value
    num_iterations = 100 # please feel free to change this value

    # Initialize theta, perform gradient descent
    theta_gradient_descent = np.zeros(len(features.columns))
    theta_gradient_descent, cost_history = gradient_descent(features_array, 
                                                            values_array, 
                                                            theta_gradient_descent, 
                                                            alpha, 
                                                            num_iterations)
    
    plot = None
  
    predictions = np.dot(features_array, theta_gradient_descent)
    return predictions, plot


def plot_cost_history(alpha, cost_history):

   cost_df = pandas.DataFrame({
      'Cost_History': cost_history,
      'Iteration': range(len(cost_history))
   })
   return ggplot(cost_df, aes('Iteration', 'Cost_History')) + \
      geom_point() + ggtitle('Cost History for alpha = %.3f' % alpha )



def plot_residuals(turnstile_weather, predictions):

    plt.figure()
    (turnstile_weather['ENTRIESn_hourly'] - predictions).hist(bins = 80)
    plt.suptitle('Residual histogram')
    plt.xlabel('Residuals')
    plt.ylabel('Frequency')
    return plt
    

def compute_r_squared(data, predictions):

    SSR = np.sum(np.square(data-predictions))
    SST = np.sum(np.square(data-np.mean(data)))
    r_squared = 1 - SSR/SST
    return r_squared
